{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKkXcVBcGUGT"
      },
      "outputs": [],
      "source": [
        "!pip -q install \"transformers>=4.41.0\" \"peft>=0.11.1\" \"accelerate>=0.30.0\" \"bitsandbytes>=0.43.1\" pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(new_session=False)"
      ],
      "metadata": {
        "id": "EFTKiBliHE4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Mistral 7B Instruct (public)\n",
        "BASE_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "# Example: If your adapter is in Google Drive, mount and point to it.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# ADAPTER_PATH = \"/content/drive/MyDrive/path/to/your_adapter\"\n",
        "ADAPTER_PATH = None  # set to your adapter dir, or leave None to test base model\n",
        "\n",
        "MAX_NEW_TOKENS = 768  # raise to 1024 if your outputs are clipped\n"
      ],
      "metadata": {
        "id": "S3kBG0gAHLAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model with 4-bit (CUDA) + tokenizer\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                # use 4-bit to fit on T4\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=dtype,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, use_fast=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL_ID,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=dtype,\n",
        ")\n",
        "\n",
        "if ADAPTER_PATH:\n",
        "    print(\"Loading LoRA adapter:\", ADAPTER_PATH)\n",
        "    model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
        "else:\n",
        "    print(\"No adapter provided; using base model only.\")\n",
        "    model = base_model\n",
        "\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "aFpUEPGGIvBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PDF upload + text extraction\n",
        "from google.colab import files\n",
        "from pypdf import PdfReader\n",
        "\n",
        "def read_pdf_text(path: str) -> str:\n",
        "    reader = PdfReader(path)\n",
        "    return \"\\n\".join([(p.extract_text() or \"\") for p in reader.pages])\n",
        "\n",
        "print(\"Upload a PDF (invoice or SOW)…\")\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "doc_text_raw = read_pdf_text(pdf_path)\n",
        "print(\"Extracted chars:\", len(doc_text_raw))\n",
        "print(doc_text_raw[:1200])\n"
      ],
      "metadata": {
        "id": "yCNEOsRQIz0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text sanitization + chunking helpers\n",
        "import re, json\n",
        "\n",
        "def clean_pdf_text(raw: str, limit=16000) -> str:\n",
        "    s = raw\n",
        "    # Kill any literal [INST]/[/INST] that might appear in OCR/headers/footers\n",
        "    s = re.sub(r\"\\[\\s*/?\\s*INST\\s*\\]\", \" \", s, flags=re.IGNORECASE)\n",
        "    # Remove bracket tags like [TOC], [FOOTER], etc.\n",
        "    s = re.sub(r\"\\[[A-Za-z0-9_/:\\- ]{1,12}\\]\", \" \", s)\n",
        "    # Remove page markers (Page 1, Page: 1, Page 3 of 5…)\n",
        "    s = re.sub(r\"\\bPage\\s*[:#]?\\s*\\d+(\\s*of\\s*\\d+)?\\b.*\", \" \", s, flags=re.IGNORECASE)\n",
        "    # Remove all-caps short header/footer lines\n",
        "    s = \"\\n\".join(\n",
        "        line for line in s.splitlines()\n",
        "        if not re.fullmatch(r\"[A-Z0-9 \\-_/]{2,40}\", line.strip())\n",
        "    )\n",
        "    # Normalize whitespace\n",
        "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
        "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
        "    return s.strip()[:limit]\n",
        "\n",
        "def choose_invoice_chunk(text: str, window_chars=2200) -> str:\n",
        "    anchors = [\n",
        "        r\"invoice\\s*(number|#|no\\.?)\", r\"\\binvoice\\b\", r\"\\bremit\\s*to\\b\",\n",
        "        r\"\\bbill\\s*to\\b\", r\"\\bdue\\s*date\\b\", r\"\\btotal\\b\", r\"\\bamount\\b\"\n",
        "    ]\n",
        "    low = text.lower()\n",
        "    for pat in anchors:\n",
        "        m = re.search(pat, low, flags=re.IGNORECASE)\n",
        "        if m:\n",
        "            i = m.start()\n",
        "            start = max(0, i - window_chars // 2)\n",
        "            end = min(len(text), start + window_chars)\n",
        "            return text[start:end]\n",
        "    return text[:window_chars]\n",
        "\n",
        "def extract_sow_mainline(text: str) -> str:\n",
        "    txt = \" \".join(text.split())\n",
        "    patterns = [\n",
        "        r\"(Statement of Work.*?entered into.*?between.*?\\.)\",\n",
        "        r\"(Statement of Work.*?between.*?\\.)\",\n",
        "        r\"(This.*?Statement of Work.*?between.*?\\.)\",\n",
        "    ]\n",
        "    for pat in patterns:\n",
        "        m = re.search(pat, txt, flags=re.IGNORECASE)\n",
        "        if m:\n",
        "            return m.group(1).strip()\n",
        "    return text[:300]\n"
      ],
      "metadata": {
        "id": "khgKZKcgJKWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt builders (Mistral [INST]…[/INST] format)\n",
        "def wrap_inst(s: str) -> str:\n",
        "    return f\"<s>[INST] {s.strip()} [/INST]\"\n",
        "\n",
        "def build_invoice_prompt(doc_text: str) -> str:\n",
        "    instr = (\n",
        "        \"You are a strict JSON extractor for INVOICE documents.\\n\"\n",
        "        \"Return ONLY one minified JSON object between <json> and </json>. No markdown, no explanations.\\n\"\n",
        "        \"Fields: title, invoice_id, bill_to, vendor, date, amount, invoice_title, \"\n",
        "        \"supplier_information, period, terms, tax, insurance, due_date, payment_method, \"\n",
        "        \"additional_text, line_items.\\n\"\n",
        "        \"Rules:\\n\"\n",
        "        \"- If a field is not present, use \\\"Missing\\\".\\n\"\n",
        "        \"- If invoice_title is missing, set it to \\\"Invoice\\\".\\n\"\n",
        "        \"- Use \\\"Remit To\\\" as vendor if available; if vendor name missing, use business_id or client_id.\\n\"\n",
        "        \"- Split vendor and bill_to into name, address, phone, email if possible.\\n\"\n",
        "        \"- Use additional_text for anything not covered.\\n\"\n",
        "        \"- Output MUST start with '{' and end with '}'.\"\n",
        "    )\n",
        "    return wrap_inst(\n",
        "        f\"{instr}\\n\\nDOCUMENT:\\n{doc_text}\\n\\nPlease output:\\n<json>\\n{{}}\\n</json>\"\n",
        "    )\n",
        "\n",
        "def build_sow_prompt(mainline_text: str) -> str:\n",
        "    instr = (\n",
        "        \"Extract contracting company and vendor from the SOW main sentence.\\n\"\n",
        "        \"Return ONLY a minified JSON object between <json> and </json> with exactly: \"\n",
        "        \"{\\\"contracting_company\\\":..., \\\"vendor\\\":...}.\\n\"\n",
        "        \"The vendor MUST appear in the main line containing the word 'between'.\\n\"\n",
        "        \"If not present there, set vendor to \\\"vendor as legal contract is missing\\\".\"\n",
        "    )\n",
        "    return wrap_inst(\n",
        "        f\"{instr}\\n\\nSENTENCE:\\n{mainline_text}\\n\\nPlease output:\\n<json>\\n{{}}\\n</json>\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "XGNuvq0fJR3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generation (token-sliced completion + JSON fallback)\n",
        "def extract_first_json(s: str):\n",
        "    # Prefer fenced <json>...</json>\n",
        "    m = re.search(r\"<json>\\s*(\\{.*?\\})\\s*</json>\", s, flags=re.S|re.I)\n",
        "    if m:\n",
        "        body = m.group(1)\n",
        "        try:\n",
        "            return json.loads(body)\n",
        "        except Exception:\n",
        "            pass\n",
        "    # Plain first {...}\n",
        "    start = s.find(\"{\")\n",
        "    end = s.rfind(\"}\")\n",
        "    if start != -1 and end != -1 and end > start:\n",
        "        try:\n",
        "            return json.loads(s[start:end+1])\n",
        "        except Exception:\n",
        "            pass\n",
        "    # Nested brace regex\n",
        "    m2 = re.search(r\"\\{(?:[^{}]|\\{[^{}]*\\})*\\}\", s, flags=re.S)\n",
        "    if m2:\n",
        "        try:\n",
        "            return json.loads(m2.group(0))\n",
        "        except Exception:\n",
        "            pass\n",
        "    # Try auto-closing truncated\n",
        "    m3 = re.search(r\"\\{.*\", s, flags=re.S)\n",
        "    if m3:\n",
        "        blob = m3.group(0)\n",
        "        opens, closes = blob.count(\"{\"), blob.count(\"}\")\n",
        "        if opens > closes:\n",
        "            blob += \"}\" * (opens - closes)\n",
        "        try:\n",
        "            return json.loads(blob)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_json(model, tokenizer, prompt_wrapped: str, max_new_tokens=768):\n",
        "    enc = tokenizer(prompt_wrapped, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
        "    input_ids = enc.input_ids.to(model.device)\n",
        "    input_len = input_ids.shape[-1]\n",
        "\n",
        "    out = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,              # deterministic\n",
        "        temperature=0.0,\n",
        "        top_p=1.0,\n",
        "        top_k=0,\n",
        "        repetition_penalty=1.02,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    # Slice completion by token length\n",
        "    tail_ids = out[0][input_len:]\n",
        "    completion = tokenizer.decode(tail_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "    js = extract_first_json(completion)\n",
        "    if js is not None:\n",
        "        return js, completion\n",
        "    return {\"error\": \"Failed to parse JSON\"}, completion\n"
      ],
      "metadata": {
        "id": "PvcbfM-DJjHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run inference (choose Invoice or SOW)\n",
        "doc_text = clean_pdf_text(doc_text_raw)\n",
        "\n",
        "# ----- pick one -----\n",
        "DOC_TYPE = \"Invoice\"   # or \"SOW\"\n",
        "\n",
        "if DOC_TYPE == \"Invoice\":\n",
        "    doc_chunk = choose_invoice_chunk(doc_text)\n",
        "    prompt = build_invoice_prompt(doc_chunk)\n",
        "else:\n",
        "    sow_mainline = extract_sow_mainline(doc_text)\n",
        "    prompt = build_sow_prompt(sow_mainline)\n",
        "\n",
        "result, raw = generate_json(model, tokenizer, prompt, max_new_tokens=MAX_NEW_TOKENS)\n",
        "print(\"=== Parsed JSON ===\")\n",
        "print(json.dumps(result, indent=2))\n",
        "print(\"\\n=== Raw Model Completion (tail) ===\")\n",
        "print(raw[:2000])\n"
      ],
      "metadata": {
        "id": "yDhqG66wJrn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}