{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6e1afa8125046668cfd404dc56cc698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bc71c9ba5a64856b58235aa675e9b27",
              "IPY_MODEL_4893539eafd1423ba008abfb8b12a7bb",
              "IPY_MODEL_8321e34b2fca408cbb103ff233c603fe"
            ],
            "layout": "IPY_MODEL_3abb82321d7a4f348803cd82da082dbf"
          }
        },
        "1bc71c9ba5a64856b58235aa675e9b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b43f1412ad4568985b9ea8c96dc090",
            "placeholder": "​",
            "style": "IPY_MODEL_2ce770032f994e84b7082bd477dae31d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4893539eafd1423ba008abfb8b12a7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f06d47c1b2d4de69c46ec2ece93ddb7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c3ee526ecda46f182d5fbdda5a1791a",
            "value": 3
          }
        },
        "8321e34b2fca408cbb103ff233c603fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_275ec6d570364514b6b074da039df298",
            "placeholder": "​",
            "style": "IPY_MODEL_8978c77fc8554cecb614c0750fae0eb9",
            "value": " 3/3 [00:20&lt;00:00,  6.71s/it]"
          }
        },
        "3abb82321d7a4f348803cd82da082dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b43f1412ad4568985b9ea8c96dc090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce770032f994e84b7082bd477dae31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f06d47c1b2d4de69c46ec2ece93ddb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3ee526ecda46f182d5fbdda5a1791a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "275ec6d570364514b6b074da039df298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8978c77fc8554cecb614c0750fae0eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "510826ae20df4990b7c0a3133a99f039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_e79b3f97ee8147ce8b4fa7631f495ea8"
          }
        },
        "a5398cb02bde4824bc7e0810d63ca45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfcbabdcc77c40789a7a8d6e57811f91",
            "placeholder": "​",
            "style": "IPY_MODEL_ff311fa027f14aba81532ceb0475c95a",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "c8f4993790a44a31889e99de780b7fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0dd0546645574bcfa8f188e559909d95",
            "placeholder": "​",
            "style": "IPY_MODEL_8e1d78b2a30b4f97a618ee475ad897c6",
            "value": ""
          }
        },
        "f0748a40721b4955bd7674ee2f0ed4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_647ae1893e1a4bd2892e96d48267a5f0",
            "style": "IPY_MODEL_29d19d43c4334991a177a205d72351fe",
            "value": true
          }
        },
        "9b66e28b2b604bd9bd12d55915ae3bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_dd6f92ca809b4dcbb57bf53440c95f28",
            "style": "IPY_MODEL_ccf5335923204bea868443476dc2b206",
            "tooltip": ""
          }
        },
        "be478e3aca3f4fed8de17ca097914615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e20b4ebc7e43ff9cf966da0fcff91e",
            "placeholder": "​",
            "style": "IPY_MODEL_01aaa66346ed418088485efcc518b69f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e79b3f97ee8147ce8b4fa7631f495ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "bfcbabdcc77c40789a7a8d6e57811f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff311fa027f14aba81532ceb0475c95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dd0546645574bcfa8f188e559909d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e1d78b2a30b4f97a618ee475ad897c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "647ae1893e1a4bd2892e96d48267a5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29d19d43c4334991a177a205d72351fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd6f92ca809b4dcbb57bf53440c95f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf5335923204bea868443476dc2b206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f4e20b4ebc7e43ff9cf966da0fcff91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01aaa66346ed418088485efcc518b69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfb644e483de4dbbaf7749b2551f4d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc2b61d18ad348489555bcc48fe04043",
            "placeholder": "​",
            "style": "IPY_MODEL_23a1ddfcc9174f73886aa52ea2e7315a",
            "value": "Connecting..."
          }
        },
        "cc2b61d18ad348489555bcc48fe04043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a1ddfcc9174f73886aa52ea2e7315a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb93321ec9814b4791f72bce0e029cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3e736c1bbd340e39304e8116886f467",
              "IPY_MODEL_2b1088f668e84380aa8dcd237a1c76d8",
              "IPY_MODEL_8117929311d343f5a7d327423c80f91b"
            ],
            "layout": "IPY_MODEL_a212017f8af24d43857393f5c9fa158c"
          }
        },
        "a3e736c1bbd340e39304e8116886f467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7fe915b36944bc49a8ea0bce40b0bcd",
            "placeholder": "​",
            "style": "IPY_MODEL_4b87957c2de841dc8a8cb989375f3d4d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2b1088f668e84380aa8dcd237a1c76d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c599992fc0a34617a7daad74194d304c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2123fe08a3b4cd6b8f917177ffa78d8",
            "value": 3
          }
        },
        "8117929311d343f5a7d327423c80f91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_763d5092db384d4f98f960656ae5d1db",
            "placeholder": "​",
            "style": "IPY_MODEL_857affc4ade348c1a3dd30ea82b1dcdd",
            "value": " 3/3 [00:21&lt;00:00,  7.21s/it]"
          }
        },
        "a212017f8af24d43857393f5c9fa158c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7fe915b36944bc49a8ea0bce40b0bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b87957c2de841dc8a8cb989375f3d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c599992fc0a34617a7daad74194d304c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2123fe08a3b4cd6b8f917177ffa78d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "763d5092db384d4f98f960656ae5d1db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "857affc4ade348c1a3dd30ea82b1dcdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VirezDh9Muet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b935857-c2f3-4ad6-ee5d-856f2add9b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers peft datasets accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(new_session=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "510826ae20df4990b7c0a3133a99f039",
            "a5398cb02bde4824bc7e0810d63ca45c",
            "c8f4993790a44a31889e99de780b7fae",
            "f0748a40721b4955bd7674ee2f0ed4b8",
            "9b66e28b2b604bd9bd12d55915ae3bc3",
            "be478e3aca3f4fed8de17ca097914615",
            "e79b3f97ee8147ce8b4fa7631f495ea8",
            "bfcbabdcc77c40789a7a8d6e57811f91",
            "ff311fa027f14aba81532ceb0475c95a",
            "0dd0546645574bcfa8f188e559909d95",
            "8e1d78b2a30b4f97a618ee475ad897c6",
            "647ae1893e1a4bd2892e96d48267a5f0",
            "29d19d43c4334991a177a205d72351fe",
            "dd6f92ca809b4dcbb57bf53440c95f28",
            "ccf5335923204bea868443476dc2b206",
            "f4e20b4ebc7e43ff9cf966da0fcff91e",
            "01aaa66346ed418088485efcc518b69f",
            "dfb644e483de4dbbaf7749b2551f4d20",
            "cc2b61d18ad348489555bcc48fe04043",
            "23a1ddfcc9174f73886aa52ea2e7315a"
          ]
        },
        "id": "Z5xQxRki3-Dg",
        "outputId": "f614f537-2611-4a78-8264-9ecbf3016774"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "510826ae20df4990b7c0a3133a99f039"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CH89xaDpK_Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Upload ZIP bundle with training script and data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "oB4e8IupONoW",
        "outputId": "e823bf6e-baef-4d17-c06c-13d4b3f47e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd88cfee-4e7a-43d5-91ec-bb732dbf7735\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fd88cfee-4e7a-43d5-91ec-bb732dbf7735\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mistralai_invoice_mapping_finetune_bundle.zip to mistralai_invoice_mapping_finetune_bundle.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Unzip the bundle\n",
        "!unzip -o mistralai_invoice_mapping_finetune_bundle.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KoLN9C8Ouy6",
        "outputId": "ce394998-099d-4d18-b276-d94df26d3411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  mistralai_invoice_mapping_finetune_bundle.zip\n",
            "  inflating: finetune_tinyllama.py   \n",
            "  inflating: train_invoice_sow_10000.jsonl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46U2_zD7QhPk",
        "outputId": "fee75534-c2a0-40c8-989c-7ba1036b45b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 12 04:31:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             44W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Run training\n",
        "!python fine_tune_mistralai_mapping_auto_eval.py --train_invoice_sow_sample.jsonl --num_train_epochs=3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-HRE4VLQjgH",
        "outputId": "b2ec6679-5b88-40b7-a73b-f9392cbbc8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-12 22:07:39.963102: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-08-12 22:07:39.980679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755036460.002276    4956 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755036460.008727    4956 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755036460.024986    4956 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755036460.025016    4956 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755036460.025019    4956 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755036460.025022    4956 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-12 22:07:40.029857: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "tokenizer_config.json: 100% 2.10k/2.10k [00:00<00:00, 15.0MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:01<00:00, 398kB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 3.96MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 3.28MB/s]\n",
            "config.json: 100% 596/596 [00:00<00:00, 4.04MB/s]\n",
            "model.safetensors.index.json: 100% 25.1k/25.1k [00:00<00:00, 92.2MB/s]\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00003-of-00003.safetensors:   0% 0.00/4.54G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.94G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:   0% 816k/4.54G [00:02<3:10:52, 396kB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:   0% 711k/4.94G [00:02<3:58:32, 345kB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:   1% 67.9M/4.54G [00:02<01:56, 38.5MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   3% 135M/4.54G [00:02<00:51, 85.5MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 754k/5.00G [00:02<4:32:15, 306kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:   1% 67.8M/4.94G [00:02<02:24, 33.7MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:   6% 269M/4.54G [00:02<00:22, 186MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:   7% 336M/4.54G [00:06<01:28, 47.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   3% 136M/5.00G [00:06<03:25, 23.6MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  10% 470M/4.54G [00:06<00:49, 81.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   5% 245M/5.00G [00:06<01:39, 47.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:   3% 129M/4.94G [00:06<04:15, 18.9MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   6% 312M/5.00G [00:07<01:31, 51.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:   5% 238M/4.94G [00:07<02:06, 37.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   7% 330M/5.00G [00:08<01:37, 47.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:   6% 305M/4.94G [00:10<02:23, 32.2MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  12% 537M/4.54G [00:10<01:33, 43.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   8% 397M/5.00G [00:10<01:54, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  13% 604M/4.54G [00:10<01:11, 55.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   9% 438M/5.00G [00:11<01:51, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:   8% 372M/4.94G [00:11<02:01, 37.7MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  15% 671M/4.54G [00:12<01:17, 50.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  10% 505M/5.00G [00:14<02:23, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:   9% 439M/4.94G [00:14<02:23, 31.3MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  16% 738M/4.54G [00:14<01:29, 42.6MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  19% 873M/4.54G [00:15<00:57, 63.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  12% 573M/4.94G [00:17<02:01, 35.8MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  22% 1.01G/4.54G [00:17<00:58, 60.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  15% 729M/5.00G [00:17<01:31, 46.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  12% 604M/4.94G [00:18<02:04, 34.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  16% 796M/5.00G [00:18<01:22, 51.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 863M/5.00G [00:20<01:21, 50.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  24% 1.07G/4.54G [00:20<01:11, 48.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  16% 806M/4.94G [00:20<01:08, 60.2MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  25% 1.14G/4.54G [00:22<01:16, 44.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  19% 930M/5.00G [00:22<01:38, 41.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  27% 1.21G/4.54G [00:23<01:09, 48.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  18% 873M/4.94G [00:23<01:34, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  20% 988M/5.00G [00:23<01:26, 46.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  28% 1.27G/4.54G [00:23<00:55, 58.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  19% 940M/4.94G [00:24<01:28, 45.2MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  30% 1.34G/4.54G [00:24<00:56, 56.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  20% 1.01G/4.94G [00:26<01:37, 40.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  21% 1.06G/5.00G [00:26<01:52, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  31% 1.41G/4.54G [00:26<01:06, 47.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  22% 1.07G/4.94G [00:27<01:13, 52.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  24% 1.20G/5.00G [00:27<01:03, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  32% 1.48G/4.54G [00:27<00:50, 61.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  23% 1.14G/4.94G [00:27<01:02, 60.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  25% 1.27G/5.00G [00:27<00:57, 65.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  34% 1.54G/4.54G [00:27<00:42, 70.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  24% 1.21G/4.94G [00:28<01:01, 60.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  27% 1.34G/5.00G [00:29<01:02, 58.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  35% 1.61G/4.54G [00:30<01:09, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  26% 1.27G/4.94G [00:30<01:16, 47.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  28% 1.41G/5.00G [00:31<01:07, 52.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  37% 1.68G/4.54G [00:31<00:50, 57.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  29% 1.43G/5.00G [00:31<01:01, 57.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  30% 1.50G/5.00G [00:32<01:08, 51.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  27% 1.34G/4.94G [00:32<01:22, 43.4MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  38% 1.75G/4.54G [00:32<00:55, 50.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  29% 1.41G/4.94G [00:35<01:32, 38.3MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  40% 1.81G/4.54G [00:35<01:05, 41.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  31% 1.54G/5.00G [00:35<01:39, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  30% 1.48G/4.94G [00:35<01:06, 51.8MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  41% 1.88G/4.54G [00:35<00:47, 56.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  32% 1.60G/5.00G [00:35<01:09, 48.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  31% 1.54G/4.94G [00:35<00:48, 69.6MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  43% 1.95G/4.54G [00:35<00:39, 66.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  33% 1.61G/4.94G [00:36<00:51, 65.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  33% 1.67G/5.00G [00:37<01:25, 39.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  34% 1.68G/4.94G [00:37<00:53, 60.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  34% 1.72G/5.00G [00:39<01:22, 39.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  44% 2.02G/4.54G [00:39<01:02, 40.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  35% 1.75G/4.94G [00:39<00:54, 58.8MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  46% 2.08G/4.54G [00:41<01:06, 37.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  36% 1.76G/4.94G [00:41<01:26, 36.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  36% 1.79G/5.00G [00:41<01:27, 36.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  47% 2.15G/4.54G [00:41<00:50, 47.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  37% 1.83G/4.94G [00:42<01:08, 45.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  37% 1.86G/5.00G [00:42<01:12, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  50% 2.28G/4.54G [00:42<00:31, 71.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  38% 1.90G/4.94G [00:45<01:33, 32.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  39% 1.93G/5.00G [00:45<01:31, 33.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  52% 2.35G/4.54G [00:45<00:46, 47.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  41% 2.03G/5.00G [00:45<00:54, 54.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  55% 2.49G/4.54G [00:45<00:26, 76.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  42% 2.09G/5.00G [00:46<00:47, 61.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  56% 2.55G/4.54G [00:46<00:28, 70.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  41% 2.01G/4.94G [00:46<01:06, 44.1MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  58% 2.62G/4.54G [00:49<00:40, 47.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  42% 2.11G/5.00G [00:49<01:34, 30.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  59% 2.69G/4.54G [00:50<00:31, 58.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  42% 2.08G/4.94G [00:50<01:23, 34.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  44% 2.18G/5.00G [00:50<01:08, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  45% 2.21G/4.94G [00:53<01:17, 35.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  45% 2.25G/5.00G [00:53<01:31, 29.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  62% 2.82G/4.54G [00:53<00:37, 46.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  46% 2.28G/4.94G [00:53<00:59, 44.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  46% 2.29G/5.00G [00:53<01:14, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  64% 2.89G/4.54G [00:54<00:30, 54.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  48% 2.35G/4.94G [00:54<00:50, 50.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  47% 2.33G/5.00G [00:55<01:15, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  65% 2.95G/4.54G [00:55<00:28, 56.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  48% 2.38G/5.00G [00:57<01:33, 28.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  49% 2.42G/4.94G [00:57<01:07, 37.2MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  67% 3.02G/4.54G [00:57<00:35, 43.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  50% 2.49G/4.94G [00:58<00:49, 49.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  50% 2.51G/5.00G [00:58<00:45, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  68% 3.09G/4.54G [00:58<00:27, 52.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  52% 2.55G/4.94G [00:59<00:49, 48.3MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  69% 3.15G/4.54G [00:59<00:26, 51.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  51% 2.54G/5.00G [01:00<01:05, 37.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  53% 2.62G/4.94G [01:00<00:48, 47.5MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  71% 3.22G/4.54G [01:01<00:29, 44.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  52% 2.61G/5.00G [01:01<00:59, 40.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  54% 2.69G/4.94G [01:01<00:42, 52.8MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  72% 3.29G/4.54G [01:02<00:24, 52.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  54% 2.72G/5.00G [01:02<00:42, 54.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  56% 2.75G/4.94G [01:03<00:42, 51.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  56% 2.78G/5.00G [01:03<00:39, 56.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  74% 3.36G/4.54G [01:04<00:23, 49.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  57% 2.82G/4.94G [01:04<00:39, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  56% 2.82G/5.00G [01:04<00:38, 56.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  75% 3.42G/4.54G [01:05<00:23, 47.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  57% 2.84G/5.00G [01:05<00:47, 45.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  58% 2.89G/4.94G [01:05<00:40, 50.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  58% 2.90G/5.00G [01:06<00:38, 54.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  77% 3.49G/4.54G [01:06<00:20, 50.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  59% 2.94G/5.00G [01:06<00:35, 58.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  60% 2.95G/4.94G [01:07<00:37, 52.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  59% 2.96G/5.00G [01:07<00:33, 61.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  78% 3.56G/4.54G [01:09<00:23, 41.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  60% 2.99G/5.00G [01:09<00:55, 36.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  60% 3.01G/5.00G [01:09<01:00, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  61% 3.02G/4.94G [01:10<00:51, 37.4MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  80% 3.62G/4.54G [01:10<00:19, 46.8MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  81% 3.69G/4.54G [01:10<00:14, 56.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  64% 3.16G/4.94G [01:10<00:29, 60.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  61% 3.06G/5.00G [01:16<02:23, 13.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  65% 3.22G/4.94G [01:16<01:00, 28.6MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  83% 3.76G/4.54G [01:16<00:30, 25.3MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  92% 4.16G/4.54G [01:17<00:04, 86.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  71% 3.49G/4.94G [01:17<00:21, 66.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  72% 3.56G/4.94G [01:17<00:17, 78.3MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  93% 4.23G/4.54G [01:17<00:03, 97.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  62% 3.09G/5.00G [01:17<01:48, 17.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  73% 3.62G/4.94G [01:17<00:14, 91.2MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  95% 4.29G/4.54G [01:19<00:03, 70.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  63% 3.16G/5.00G [01:19<01:32, 19.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  75% 3.69G/4.94G [01:20<00:23, 52.4MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  96% 4.36G/4.54G [01:21<00:03, 54.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  76% 3.76G/4.94G [01:22<00:24, 48.0MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  97% 4.43G/4.54G [01:22<00:01, 60.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  65% 3.24G/5.00G [01:22<01:13, 24.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  77% 3.83G/4.94G [01:22<00:18, 60.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  79% 3.89G/4.94G [01:23<00:15, 67.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  66% 3.31G/5.00G [01:23<00:55, 30.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors:  99% 4.47G/4.54G [01:28<00:02, 27.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  80% 3.96G/4.94G [01:28<00:31, 31.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  67% 3.37G/5.00G [01:28<01:15, 21.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  83% 4.09G/4.94G [01:28<00:16, 52.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  70% 3.48G/5.00G [01:28<00:41, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  84% 4.16G/4.94G [01:29<00:13, 59.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  71% 3.55G/5.00G [01:29<00:32, 44.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  72% 3.58G/5.00G [01:29<00:28, 49.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  85% 4.22G/4.94G [01:29<00:09, 72.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  72% 3.60G/5.00G [01:29<00:27, 50.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.64G/5.00G [01:30<00:21, 62.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.67G/5.00G [01:32<00:39, 33.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  87% 4.29G/4.94G [01:32<00:13, 47.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  77% 3.83G/5.00G [01:32<00:14, 81.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  90% 4.43G/4.94G [01:32<00:06, 74.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  77% 3.87G/5.00G [01:33<00:15, 74.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  91% 4.49G/4.94G [01:33<00:06, 72.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  78% 3.90G/5.00G [01:34<00:16, 66.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  79% 3.94G/5.00G [01:35<00:19, 54.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  92% 4.56G/4.94G [01:36<00:06, 55.2MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors: 100% 4.54G/4.54G [01:36<00:00, 47.3MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  80% 4.01G/5.00G [01:36<00:18, 55.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  94% 4.63G/4.94G [01:36<00:04, 63.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  81% 4.06G/5.00G [01:36<00:13, 70.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  95% 4.69G/4.94G [01:36<00:03, 80.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  83% 4.13G/5.00G [01:37<00:11, 78.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  96% 4.76G/4.94G [01:37<00:02, 79.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  83% 4.15G/5.00G [01:37<00:11, 74.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  98% 4.83G/4.94G [01:39<00:02, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  84% 4.22G/5.00G [01:40<00:19, 40.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors:  99% 4.90G/4.94G [01:40<00:00, 58.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  88% 4.39G/5.00G [01:40<00:06, 93.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00003.safetensors: 100% 4.94G/4.94G [01:41<00:00, 48.8MB/s]\n",
            "Fetching 3 files:  33% 1/3 [01:41<03:23, 101.85s/it]\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  90% 4.51G/5.00G [01:41<00:03, 125MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  92% 4.60G/5.00G [01:41<00:02, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  93% 4.66G/5.00G [01:41<00:01, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  95% 4.73G/5.00G [01:41<00:01, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  95% 4.77G/5.00G [01:42<00:01, 207MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  97% 4.87G/5.00G [01:42<00:00, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  99% 4.93G/5.00G [01:42<00:00, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors: 100% 5.00G/5.00G [01:42<00:00, 48.6MB/s]\n",
            "Fetching 3 files: 100% 3/3 [01:43<00:00, 34.44s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:22<00:00,  7.65s/it]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 899kB/s]\n",
            "trainable params: 13,631,488 || all params: 7,255,363,584 || trainable%: 0.1879\n",
            "Generating train split: 500 examples [00:00, 20576.25 examples/s]\n",
            "Map: 100% 500/500 [00:00<00:00, 718.29 examples/s]\n",
            "/content/fine_tune_mistralai_mapping_auto_eval.py:196: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "Sanity loss: tensor(0.6423, device='cuda:0', grad_fn=<NllLossBackward0>) requires_grad: True\n",
            "Any trainable param has grad: True\n",
            "{'loss': 0.217, 'grad_norm': 0.12362583726644516, 'learning_rate': 9.732198865788047e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0022, 'grad_norm': 0.03746999055147171, 'learning_rate': 7.447089239055428e-05, 'epoch': 1.26}\n",
            "{'loss': 0.002, 'grad_norm': 0.03377838060259819, 'learning_rate': 3.9128491220922156e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0015, 'grad_norm': 0.046997036784887314, 'learning_rate': 9.335512963221732e-06, 'epoch': 2.51}\n",
            "{'train_runtime': 2051.6888, 'train_samples_per_second': 0.731, 'train_steps_per_second': 0.047, 'train_loss': 0.046611132740508765, 'epoch': 3.0}\n",
            "100% 96/96 [34:11<00:00, 21.37s/it]\n",
            "Saved LoRA adapter to: ./mistral_lora_map_invoice_500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4Lm9JIB38DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV406lLvinNK",
        "outputId": "70a532ec-b0a3-48a4-e843-cdfb96ea41c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"output_lora_mistralai_invoice_500\", \"zip\", \"mistral_lora_map_invoice_500\")\n",
        "from google.colab import files\n",
        "files.download(\"output_lora_mistralai_invoice_500.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gisKwLsoi0BQ",
        "outputId": "a76d1700-222d-4f4a-9453-bb876efe09a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_63c2a1de-7067-4588-b2e8-4347163a8f15\", \"output_lora_mistralai_invoice_500.zip\", 126840202)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"transformers>=4.41.0\" \"peft>=0.11.1\" \"accelerate>=0.30.0\" \"bitsandbytes>=0.43.1\" datasets trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSqPcDQ2OryJ",
        "outputId": "f1e88453-8676-49b3-adb5-0433148c448c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.41.0 in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: peft>=0.11.1 in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: accelerate>=0.30.0 in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: bitsandbytes>=0.43.1 in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Collecting trl\n",
            "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft>=0.11.1) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft>=0.11.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.41.0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.41.0) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.0) (2025.8.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft>=0.11.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft>=0.11.1) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft>=0.11.1) (3.0.2)\n",
            "Downloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trl\n",
            "Successfully installed trl-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U trl>=0.8.6"
      ],
      "metadata": {
        "id": "94smw2NdPRFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python fine_tune_mistralai_mapping_auto_eval.py \\\n",
        "  --train_file train_invoice_sow_sample.jsonl \\\n",
        "  --output_dir ./mistral_lora_map_invoice_500 \\\n",
        "  --eval_ratio 0 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --per_device_train_batch_size 2 \\\n",
        "  --grad_accum 8 \\\n",
        "  --learning_rate 1e-4 \\\n",
        "  --warmup_ratio 0.1 \\\n",
        "  --bf16 \\\n",
        "  --sample_print_steps 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BObqrlqQN8jJ",
        "outputId": "4b7b9e4e-f561-421a-ca55-d0d992e09899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-12 21:59:59.562599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755035999.604987   12644 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755035999.618366   12644 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755035999.657702   12644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755035999.657742   12644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755035999.657751   12644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755035999.657759   12644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading checkpoint shards: 100% 3/3 [01:15<00:00, 25.22s/it]\n",
            "trainable params: 13,631,488 || all params: 7,255,363,584 || trainable%: 0.1879\n",
            "/content/fine_tune_mistralai_mapping_auto_eval.py:196: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "Sanity loss: tensor(0.6423, device='cuda:0', grad_fn=<NllLossBackward0>) requires_grad: True\n",
            "Any trainable param has grad: True\n",
            "  0% 0/64 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"/content/fine_tune_mistralai_mapping_auto_eval.py\", line 222, in <module>\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2238, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2582, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3845, in training_step\n",
            "    self.accelerator.backward(loss, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\", line 2578, in backward\n",
            "    loss.backward(**kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 307, in apply\n",
            "    return user_fn(self, *args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\", line 304, in backward\n",
            "    outputs = ctx.run_function(*detached_inputs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\", line 243, in forward\n",
            "    hidden_states = self.mlp(hidden_states)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\", line 46, in forward\n",
            "    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py\", line 565, in forward\n",
            "    return bnb.matmul_4bit(x, weight, bias=bias, quant_state=self.weight.quant_state).to(inp_dtype)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py\", line 466, in matmul_4bit\n",
            "    return MatMul4Bit.apply(A, B, out, bias, quant_state)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py\", line 380, in forward\n",
            "    output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 86.12 MiB is free. Process 10156 has 8.22 GiB memory in use. Process 192266 has 6.43 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 372.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "  0%|          | 0/64 [00:10<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"mistral_lora_mapping_training\", \"zip\", \"mistral_lora_map\")\n",
        "from google.colab import files\n",
        "files.download(\"mistral_lora_mapping_training.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YtRNtzixe3Gz",
        "outputId": "28872eab-08d0-4a74-e75d-9ad85f2696a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_55aea679-7220-4e81-a359-29fa07e7fefc\", \"mistral_lora_mapping_training.zip\", 126923657)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inference using sample\n",
        "import torch, json, re\n",
        "from peft import PeftModel\n",
        "import os\n",
        "os.environ.setdefault(\"BITSANDBYTES_NOWELCOME\", \"1\")\n",
        "os.environ.setdefault(\"LD_LIBRARY_PATH\", \"/usr/lib64-nvidia\")\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "BASE_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "ADAPTER_DIR = \"/content/mistral_lora_map_invoice_500\"       # from training output\n",
        "MAX_NEW = 768\n",
        "\n",
        "bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "tok = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "base = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map=\"auto\", quantization_config=bnb)\n",
        "model = PeftModel.from_pretrained(base, ADAPTER_DIR).eval()\n",
        "\n",
        "def wrap_inst(s): return f\"<s>[INST] {s.strip()} [/INST]\"\n",
        "\n",
        "def extract_first_json(s: str):\n",
        "    m = re.search(r\"<json>\\s*(\\{.*?\\})\\s*</json>\", s, flags=re.S|re.I)\n",
        "    if m:\n",
        "        try: return json.loads(m.group(1))\n",
        "        except: pass\n",
        "    start = s.find(\"{\"); end = s.rfind(\"}\")\n",
        "    if start!=-1 and end!=-1 and end>start:\n",
        "        try: return json.loads(s[start:end+1])\n",
        "        except: pass\n",
        "    return None\n",
        "\n",
        "def infer_invoice(doc_text: str):\n",
        "    instr = (\n",
        "        \"You are a strict JSON extractor for INVOICE documents.\\n\"\n",
        "        \"Return ONLY one minified JSON object between <json> and </json>. No markdown, no explanations.\\n\"\n",
        "        \"Fields: title, invoice_id, bill_to, vendor, date, amount, \"\n",
        "        \"supplier_information, period, terms, tax, insurance, due_date, payment_method, \"\n",
        "        \"additional_text, line_items.\\n\"\n",
        "        \"Rules:\\n\"\n",
        "        \"- If a field is not present, use \\\"Missing\\\".\\n\"\n",
        "        \"- If invoice_title is missing, set it to \\\"Invoice\\\".\\n\"\n",
        "        \"- Use \\\"Remit To\\\" as vendor if available; if vendor name missing, use business_id or client_id.\\n\"\n",
        "        \"- Split vendor and bill_to into name, address, phone, email if possible.\\n\"\n",
        "        \"- Use additional_text for anything not covered.\\n\"\n",
        "        \"- Output MUST start with '{' and end with '}'.\"\n",
        "    )\n",
        "    prompt = wrap_inst(f\"{instr}\\n\\nDOCUMENT:\\n{doc_text}\\n\\nPlease output:\\n<json>\\n{{}}\\n</json>\")\n",
        "\n",
        "    enc = tok(prompt, return_tensors=\"pt\", truncation=True, max_length=4096).to(model.device)\n",
        "    input_len = enc.input_ids.shape[-1]\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **enc,\n",
        "            max_new_tokens=MAX_NEW,\n",
        "            do_sample=False,\n",
        "            temperature=0.0,\n",
        "            top_p=1.0,\n",
        "            top_k=0,\n",
        "            repetition_penalty=1.02,\n",
        "            eos_token_id=tok.eos_token_id,\n",
        "            pad_token_id=tok.eos_token_id,\n",
        "        )\n",
        "    tail = out[0][input_len:]\n",
        "    text = tok.decode(tail, skip_special_tokens=True)\n",
        "    return extract_first_json(text), text\n",
        "\n",
        "# tiny test\n",
        "doc = \"Invoice # TB32\\nRemit To: Panacea Direct Inc, Jersey City, NJ\\nBill To: Netwoven Inc\\nDate: 2025-05-01\\nTotal Amount: $22,560.00\\nTerms: Net 30\"\n",
        "js, raw = infer_invoice(doc)\n",
        "print(js)\n",
        "print(raw[:800])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "e6e1afa8125046668cfd404dc56cc698",
            "1bc71c9ba5a64856b58235aa675e9b27",
            "4893539eafd1423ba008abfb8b12a7bb",
            "8321e34b2fca408cbb103ff233c603fe",
            "3abb82321d7a4f348803cd82da082dbf",
            "00b43f1412ad4568985b9ea8c96dc090",
            "2ce770032f994e84b7082bd477dae31d",
            "1f06d47c1b2d4de69c46ec2ece93ddb7",
            "3c3ee526ecda46f182d5fbdda5a1791a",
            "275ec6d570364514b6b074da039df298",
            "8978c77fc8554cecb614c0750fae0eb9"
          ]
        },
        "id": "2hjVUv4cfgrM",
        "outputId": "54e8aae1-f993-4889-ab4d-76c9add8d52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e1afa8125046668cfd404dc56cc698"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "<json>{\"title\":\"Invoice\",\"invoice_id\":\"TB32\",\"bill_to\":{\"name\":\"Netwoven Inc\",\"address\":\"Missing\",\"phone\":\"Missing\",\"email\":\"Missing\"},\"vendor\":{\"name\":\"Panacea Direct Inc\",\"address\":\"Jersey City, NJ\",\"phone\":\"Missing\",\"email\":\"Missing\"},\"date\":\"2025-05-01\",\"amount\":22560.0,\"supplier_information\":{\"missing\"},\"period\":{\"start\":\"Missing\",\"end\":\"Missing\"},\"terms\":\"Net 30\",\"tax\":{\"missing},\"insurance\":{\"missing},\"due_date\":\"Missing\",\"payment_method\":\"Missing\",\"additional_text\":\"Missing\",\"line_items\":{\"missing}}</json>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inference using pdf\n",
        "# %%capture\n",
        "!pip -q install \"transformers>=4.41.0\" \"peft>=0.11.1\" \"accelerate>=0.30.0\" \"bitsandbytes>=0.43.1\" pypdf\n",
        "import re, json, torch\n",
        "from pypdf import PdfReader\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "# === CONFIG ===\n",
        "BASE_MODEL   = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "ADAPTER_DIR  = \"/content/sample_data/\"  # your trained LoRA output dir\n",
        "MAX_NEW      = 768\n",
        "MAX_DOC_CHARS = 18000  # cap input text to keep within context\n",
        "\n",
        "# === Load model ===\n",
        "bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "tok = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "base = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map=\"auto\", quantization_config=bnb)\n",
        "model = PeftModel.from_pretrained(base, ADAPTER_DIR).eval()\n",
        "\n",
        "def wrap_inst(s: str) -> str:\n",
        "    return f\"<s>[INST] {s.strip()} [/INST]\"\n",
        "\n",
        "def read_pdf_text(path: str) -> str:\n",
        "    r = PdfReader(path)\n",
        "    parts = []\n",
        "    for i, page in enumerate(r.pages):\n",
        "        try:\n",
        "            t = page.extract_text() or \"\"\n",
        "            # Keep page markers lightly to avoid <INST> confusion\n",
        "            parts.append(f\"\\n--- Page {i+1} ---\\n{t}\")\n",
        "        except Exception:\n",
        "            continue\n",
        "    text = \"\\n\".join(parts)\n",
        "    # sanitize stray bracket sequences that might confuse chat template\n",
        "    text = text.replace(\"[/INST]\", \" \").replace(\"[INST]\", \" \")\n",
        "    return text[:MAX_DOC_CHARS]\n",
        "\n",
        "def build_invoice_prompt(doc_text: str) -> str:\n",
        "    instr = (\n",
        "        \"You are a strict JSON extractor for INVOICE documents.\\n\"\n",
        "        \"Return ONLY one minified JSON object between <json> and </json>. No markdown, no explanations.\\n\"\n",
        "        \"Fields: title, invoice_id, bill_to, vendor, date, amount, \"\n",
        "        \"supplier_information, period, terms, tax, insurance, due_date, payment_method, \"\n",
        "        \"additional_text, line_items.\\n\"\n",
        "        \"Rules:\\n\"\n",
        "        \"- If a field is not present, set it to \\\"Missing\\\".\\n\"\n",
        "        \"- If invoice_title or title is missing, set it to \\\"Invoice\\\".\\n\"\n",
        "        \"- line_items can have more than one line. Please extract all fields from line. unitprice may show as 2 words unit and price. QTY or qty or quantity is quantity.\\n\"\n",
        "        \"- \\\"additional notes\\\"  may refer to additional_text.\\n\"\n",
        "        \"- Use \\\"Remit To\\\" as vendor if available; if vendor name missing, use business_id or client_id.\\n\"\n",
        "        \"- Split vendor and bill_to into name, address, phone, email if possible.\\n\"\n",
        "        \"- Use additional_text for any content not covered by fields.\\n\"\n",
        "        \"- Output MUST start with '{' and end with '}' and be wrapped in <json>...</json>.\"\n",
        "    )\n",
        "    return wrap_inst(f\"{instr}\\n\\nDOCUMENT:\\n{doc_text}\\n\\nPlease output:\\n<json>\\n{{}}\\n</json>\")\n",
        "\n",
        "def extract_first_json(s: str):\n",
        "    m = re.search(r\"<json>\\s*(\\{.*?\\})\\s*</json>\", s, flags=re.S|re.I)\n",
        "    if m:\n",
        "        try: return json.loads(m.group(1))\n",
        "        except: pass\n",
        "    # fallback: best-effort brace slice\n",
        "    start = s.find(\"{\"); end = s.rfind(\"}\")\n",
        "    if start!=-1 and end!=-1 and end>start:\n",
        "        try: return json.loads(s[start:end+1])\n",
        "        except: pass\n",
        "    return None\n",
        "\n",
        "def infer_invoice_from_pdf(pdf_path: str):\n",
        "    doc_text = read_pdf_text(pdf_path)\n",
        "    prompt = build_invoice_prompt(doc_text)\n",
        "    enc = tok(prompt, return_tensors=\"pt\", truncation=True, max_length=4096).to(model.device)\n",
        "    input_len = enc.input_ids.shape[-1]\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **enc,\n",
        "            max_new_tokens=MAX_NEW,\n",
        "            do_sample=False,\n",
        "            temperature=0.0,\n",
        "            top_p=1.0,\n",
        "            top_k=0,\n",
        "            repetition_penalty=1.02,\n",
        "            eos_token_id=tok.eos_token_id,\n",
        "            pad_token_id=tok.eos_token_id,\n",
        "        )\n",
        "    tail = out[0][input_len:]\n",
        "    text = tok.decode(tail, skip_special_tokens=True)\n",
        "    parsed = extract_first_json(text)\n",
        "    return parsed, text\n",
        "\n",
        "# === Upload + test (Colab) ===\n",
        "from google.colab import files\n",
        "print(\"Upload 1+ invoice PDFs …\")\n",
        "uploaded = files.upload()\n",
        "for name, _ in uploaded.items():\n",
        "    js, raw = infer_invoice_from_pdf(name)\n",
        "    print(\"\\n==== File:\", name, \"====\")\n",
        "    if js is None:\n",
        "        print(\"Failed to parse JSON. Raw tail:\\n\", raw[-1200:])\n",
        "    else:\n",
        "        print(json.dumps(js, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bb93321ec9814b4791f72bce0e029cc3",
            "a3e736c1bbd340e39304e8116886f467",
            "2b1088f668e84380aa8dcd237a1c76d8",
            "8117929311d343f5a7d327423c80f91b",
            "a212017f8af24d43857393f5c9fa158c",
            "f7fe915b36944bc49a8ea0bce40b0bcd",
            "4b87957c2de841dc8a8cb989375f3d4d",
            "c599992fc0a34617a7daad74194d304c",
            "e2123fe08a3b4cd6b8f917177ffa78d8",
            "763d5092db384d4f98f960656ae5d1db",
            "857affc4ade348c1a3dd30ea82b1dcdd"
          ]
        },
        "id": "skbAX0r2nUkc",
        "outputId": "7831211a-4d46-4490-ede6-37bd3c5bdf99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb93321ec9814b4791f72bce0e029cc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload 1+ invoice PDFs …\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b295778d-2af4-4e53-98d0-c04f6c214fdf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b295778d-2af4-4e53-98d0-c04f6c214fdf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TB32.pdf to TB32.pdf\n",
            "\n",
            "==== File: TB32.pdf ====\n",
            "{\n",
            "  \"title\": \"Invoice\",\n",
            "  \"invoice_id\": \"TB32\",\n",
            "  \"bill_to\": {\n",
            "    \"name\": \"NETWOVEN INC\",\n",
            "    \"address_lines\": [\n",
            "      \"4000 PIMLICO DR STE 114 103\",\n",
            "      \"PLEASANTON, CA 945883474\",\n",
            "      \"USA\"\n",
            "    ],\n",
            "    \"phone\": \"(408) 666-2533\"\n",
            "  },\n",
            "  \"vendor\": {\n",
            "    \"name\": \"Panacea Direct Inc\",\n",
            "    \"address_lines\": [\n",
            "      \"Journal Square\",\n",
            "      \"4th Floor Suite#459\",\n",
            "      \"Jersey City, NJ 07306\",\n",
            "      \"US\"\n",
            "    ],\n",
            "    \"phone\": \"(412) 983-2222\"\n",
            "  },\n",
            "  \"date\": \"Invoice Date\",\n",
            "  \"terms_days\": 30,\n",
            "  \"due_date\": \"05/31/2025\",\n",
            "  \"line_items\": [\n",
            "    {\n",
            "      \"line_no\": 1,\n",
            "      \"description\": \"Ayan Thaddeus Shaw Consulting Services for AMD\",\n",
            "      \"qty\": 160,\n",
            "      \"unit_price\": 141.0,\n",
            "      \"subtotal\": 22560.0\n",
            "    }\n",
            "  ],\n",
            "  \"subtotal\": 22560.0,\n",
            "  \"tax\": 0.0,\n",
            "  \"insurance\": \"Missing\",\n",
            "  \"service_period\": {\n",
            "    \"start\": \"3/29/2025\",\n",
            "    \"end\": \"4/25/2025\"\n",
            "  },\n",
            "  \"total_amount\": 22560.0,\n",
            "  \"balance_due\": 22560.0,\n",
            "  \"payment_method\": \"Missing\",\n",
            "  \"additional_text\": \"Additional Notes\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "\n",
        "# 1) Move big models off GPU then drop references\n",
        "try:\n",
        "    model.to(\"cpu\")\n",
        "except Exception:\n",
        "    pass\n",
        "for obj in [\"model\", \"base\", \"peft_model\", \"pipe\", \"optimizer\", \"dataloader\"]:\n",
        "    if obj in globals():\n",
        "        globals()[obj] = None\n",
        "\n",
        "# 2) Collect Python garbage\n",
        "gc.collect()\n",
        "\n",
        "# 3) Tell PyTorch to release cached VRAM back to the driver\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()   # helps in multi-process/IPC scenarios\n"
      ],
      "metadata": {
        "id": "I1KaHOProbzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python fine_tune_mistralai_mapping_with_eval.py \\\n",
        "  --train_file train_invoice_sow_sample.jsonl \\\n",
        "  --output_dir ./mistral_lora_map_udated \\\n",
        "  --eval_ratio 0 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --per_device_train_batch_size 2 \\\n",
        "  --grad_accum 8 \\\n",
        "  --learning_rate 1e-4 \\\n",
        "  --warmup_ratio 0.1 \\\n",
        "  --bf16 \\\n",
        "  --sample_print_steps 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20YaGLoapr27",
        "outputId": "e71d5330-779d-4ade-e83d-5e6d3a1d2e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-10 20:31:52.100933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754857912.122068   62393 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754857912.128599   62393 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754857912.145446   62393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754857912.145475   62393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754857912.145478   62393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754857912.145481   62393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Loading checkpoint shards: 100% 3/3 [00:17<00:00,  5.71s/it]\n",
            "trainable params: 13,631,488 || all params: 7,255,363,584 || trainable%: 0.1879\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fine_tune_mistralai_mapping_with_eval.py\", line 183, in <module>\n",
            "    eval_ds  = Dataset.from_list(eval_rows).map(map_fn, batched=False)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\", line 1054, in from_list\n",
            "    mapping = {k: [r.get(k) for r in mapping] for k in mapping[0]} if mapping else {}\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\", line 1054, in <dictcomp>\n",
            "    mapping = {k: [r.get(k) for r in mapping] for k in mapping[0]} if mapping else {}\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\", line 1054, in <listcomp>\n",
            "    mapping = {k: [r.get(k) for r in mapping] for k in mapping[0]} if mapping else {}\n",
            "                   ^^^^^\n",
            "AttributeError: 'str' object has no attribute 'get'\n"
          ]
        }
      ]
    }
  ]
}